o how do we measure it? Inside of the Elite Context Engineering Codebase, we can break down how exactly we'll measure our context in our Cloud Code agents. We have two primary modes of measuring context. our agent and context we might add to our agent. If we spin up a cloud code instance, you can see here we have some context problems already that we'll work through. We can type slash context and see all the context in our agent's context window. This is your most important tool for measuring and therefore managing your context window. It shows you exactly how much stuff your agent will work through with every prompt execution. You can see here we are absolutely torching or closing. We have 63 K tokens already spent on boot up.

If you never run slash context, you will not find this information and you will not know that we've already spent 31% of our available context window. Second mechanism for understanding context is token counters. In the bottom right of my instance here, you can see I have a token counter counting the number of tokens highlighted and in the file. We have 2,600 tokens available in the the readme. So anytime our agent interacts with the readme, which is a high touch point for agents, they'll consume 2000 tokens if they read the entire file. Measuring your context is foundational. Every context engineering technique we build from here, depends on this. If you aren't actively paying attention to the state of your agent's context, you're just vibe coding and you'll only be able to tackle the lowest hanging fruit, which is already a massively saturated space. To push further, you must learn to see from your agent's perspective. What gets measured gets managed.

So measure your context window. Use slash context and install a tokenizer right in your IDE so you know what's coming into your agent's context window. Do not load MCP servers unless you need them. Take a look at how much of my Claude Code Opus tokens are being chewed up by MCP tools. 1 thousand. Okay, this is 12% of the entire available context window. It's very likely you're wasting tokens with MCP servers you're not actively using. This is a simple, easy beginner context engineering mistake to make. Thankfully, the solution is simple. Be very purposeful with your MCP servers.

If we open up the directory here, you can see we have a variety of MCP servers. Inside of the . json file, we have a bad practice of context engineering inside of this code base. We have a default. json file that is always loading into the context window of our agents. Just four MCP servers, it's consuming 24k tokens. Let's round down that that's 10% of our entire 200k token context window chewing up expensive valuable Claude Opus tokens. You might have a model in the future. Regardless of your model, context management is still critically important. 10k tokens is 5% of your entire 200k context window.

This means 5% less work you can do with this swing of your agent. And if you boot up five agents over an hour, that's 25% of a context window in total, completely wasted, okay? unless you're always using every single MCP server, which I highly doubt. Okay, as you can see, these numbers will stack up against you very quickly. The first thing I recommend doing is get rid of this . Just completely delete this thing. Don't use a default. json for your code base. All right. And why is that?

It's because right away clears up our context window. If we type cloud now context, we've just saved some 20,000 tokens by not preloading any Okay, do not assume you need these. If you do need these, I recommend you fire these up by hand. The cracked cloud code team at Anthropic has a couple of quick, simple, easy command line flags you can use. Claude-smc config and now you just pass it on to the command line. pass in the config you want. So let's say I just wanted the fire crawl MCP server. You can see I have this specialized file here that pulls in just the file crawl MCP server and I've self-fixed it with 4K. So I know exactly how many tokens are going to get consumed by default. fault every time okay so I can copy the path to this paste that there and if you do have some globals that you want to overwrite you can use dash dash strict MCP config and then you can fire this off and check this out when we run slash context we're only going to get that 6k tokens strictly from the fire crawl mcp server and now we can kick off this specialized agent focused on just this one mcp server all right and if you do need every single mcp server explicitly reference it be very conscious with the state going into your context window.

There are many places to be wasteful as an engineer to move fast and break things. The context window of your agents is not one of them. Here, we are of course using the R in the R&D framework. We are reducing. So you might think this is not a big deal, but you have to think about every single agent instance you boot up. Okay, we're talking about tens and hundreds. And as you scale up, this bad practice will bleed into your leverage points of agentic coding. Okay, they scale all the way in to your ADWs. Only use these MCP servers when you explicitly need them because they come with a cost. This technique is controversial especially for beginners but I strongly recommend context priming over using a claw.

md or any similar auto loading memory file while this seems convenient at first it creates problems as you scale your agentic code coding across different tasks. So what is context priming and why is it superior to a memory file and why is it superior to Claude. Let's first double click into Claude. There's nothing inherently wrong with this file. most technology it's how it's used that's the problem if we boot up a new instance here you can see right away uh we have this error message let's address this now okay we have built up a massive and i mean massive claw. md file if we run slash context once again and monitor what's going on here. We've cleaned up our MCP servers, but we haven't cleaned up is this massive memory file. We have a 23,000 token memory file, again, chewing up about 10% of our entire context window of expensive opus tokens. I'm of course exaggerating my claw. md file here just to showcase this idea but I can almost guarantee you there's an engineer out there somewhere with a claw.

md file that is you know 3,000 lines long. And why is that? It's because they and their team, they've just constantly added additional items to their memory over and over and over and over again until it's become what it is now. Okay, a massive glob of mess. Okay, even the cloud code engineers built in a warning here for us large cloud. md will impact performance. What they're really saying here is there's a big chunk of state in the context window that will likely change the outcome and determine. from the outcome you're looking for. The claw. md file is incredible for one reason.

It's a reusable memory file that's always loaded into your agent's context window. Simultaneously, a claw. md file is terrible for the exact same file. It's a reusable memory file that's always loaded into your agent's context window. So why is that a problem? The problem with always on context is that it's not dynamic or controllable. Engineering work inside of code bases constantly changes, but the The cloud. md file only grows. Over time, as you and your team add more information, the file grows and grows, and eventually becomes bloated with context that isn't relevant to every engineering task. And this is the key.

Eventually, it's not gonna be relevant for the work you're doing. It's going to have useless context in your precious context window. And in the worst case, it's going to have contradictory information inside of your context window. That is the worst possible case. And this will happen if you just keep growing your memory. All right. So what's the solution here? The solution is context priming. Let's trim down, right? Let's use this flaw.

concise, right? It's a lot simpler. It's something that we always want to add, you know, and take a look at this, right? It's only 43 lines and it's just got some you know, mock structure for this code base. And these are just some things that we always want every single agent to have. I have to keep stressing that because this is the reality of the memory file. It will always be added. So copy this. We'll clean this up, save that, reset our agent here. CLD is an alias.

You can check out all the aliases I'm going to run throughout this lesson at the bottom of the readme. You can see all the aliases right here. All right, so now we have a concise MD5. The warning is gone. We can type slash context and check this out. Our context window on boot up on startup is looking much, much better. 92% free. What's left right? Our small memory file is down to 0. right 350 tokens.

This is great. This is a clear focus agent. Now, what do we use instead of this large memory file? We should context prime. What does that mean? Let me show you slash prime and we hit enter. Context priming. is when you use a dedicated reusable prompt, aka a custom slash command, to set up your agent's initial context window specifically for the task type at hand. So with every code base, I always set up Claude Command, You can see here we have two prime commands in this code base. Priming is just a reusable prompt.

We can take a look at this right here. It's very simple. It has a concise structure, right? We have the purpose. We have our run step. We have our read step and our report step. Okay, now our agent is ready to go. So it's read a couple files, it's read the readme, it understands the structure of the code base. And now if we type context, our agent has a little bit of information about this code base for this specific problem set. And so this problem set is, of course, just gaining a general understanding of our code base.

So instead of relying on a static, always loaded memory file, we're using context priming to gain full control over the initial context of our agents this is very powerful unlike the memory file we can prime against several different areas of focus in our code base okay so imagine a you know prime bug command right for bug smashing imagine a prime chore or prime feature or like we have in this code base prime cc okay this is a focused prompt it's our hot loading memory file for operating with cloud code and updating the cloud code files inside of this code base Okay. And so, you know, you can see it looks very similar. We're actually running the base prime command right from the prime CC command. So we're stacking prompts to better manage our context window. And then you can see here we're just saying read a couple extra files and do the same thing. Same thing, report your understanding of the code base. Even with this small example, elite context engineering code base, there's already room for specialization. Are we working on the app level or are we working on the cloud agent level? And as you know, from tab, We are talking here whenever we're working on the agents, we're talking about the agentic layer, right? We're working on the agentic layer.

We're building the system that builds the system. So prime, don't default. Your claw. md file should be showing trunk to contain only the absolute universal essentials that you're 100% sure you want loaded 100% of the time. You see how powerful that conditional is and how strict that conditional is. So be very careful with these memory files. Keep them slim and instead prefer context priming. This way you can build up many areas of focus for your agents. And if you find yourself coming back to some specific area of focus, build out a prime command for that specific agent. area of focus for you and your team.

This is the beginning of a big agentic level technique that we're gonna talk about in this lesson. You can see we have this new experts directory. We'll talk about that at the end of this lesson. So now we enter the interface intermediate zone. Let's enter the intermediate zone of context engineering and talk about controlling your output tokens. Output tokens are nearly always the most expensive part of your agent. Output tokens are priced anywhere from 3 to 5x the price of your input tokens. That means one write costs you up to five times more. Output tokens burn your compute and therefore burn a hole in your wallet fast. Thankfully, We can micromanage this just a little bit with output styles to limit and specify the types of output you want cloud code to have and therefore the number of output tokens cloud code will generate when responding.

It's important to note a lot of the output tokens are chewed up when you're actually writing and generating files. And when cloud code is returning large chunks back to you, there's not a lot you can do about this, but we can control the responses cloud code has directly to you. Now we can showcase that with a cloud code settings file. So inside of our dot cloud directory here, we have settings. All right. So I'm going to copy the path to this and you can see it has an output style specified. It has a one word output style. All right, so let's see how powerful this can be. Claude in YOLO mode with Sonnet. Specify a settings file right here and kick this off.

Now we'll just type something simple here. We'll just say hi, and then we'll open up another terminal side by side and type Claude. So you can see here, our agent just said done. So it's not interested in talking to us. It's not interested in chewing up output tokens. Now here on the right side, if we type output styles, you can see we're running the default. And let me actually go ahead and get this in YOLO mode here as well, running the Sonnet model. Output styles here, we have default. And if we say hi here, we're of course going to get a normal response coming out of cloud code. So right away, with just a hi, we are getting a.

massive difference in output tokens. And keep in mind, these are output tokens, right? Let's kick this up, right? Let me show you the scale in which this is important. Let's run a classic prompt. What does this code base do? And I'm going to copy that, kick it off here, kick it off So these are both the sonnet models. They're both going down their non-deterministic path. Here is our verbose on the right, and here is our one word on the left. So again, just take note of the difference here, right?

And let's go ahead and run slash context on the left. slash context on the right. And let's just briefly look at the output tokens here. So we can see there's no difference in token usage yet. In fact, our concise agent has actually spent a few more tokens reading in and looking for files. Okay, let's keep pushing this. and get out of the non-deterministic nature, right? Let's find the average here. Okay, I'm gonna fire this off here and I'm gonna fire this off here, okay? And so what we're doing here is we're reading some documentation in AI docs.

We can pull this up right here. It's cloud code, TypeScript, SDK documentation. and we're letting our agents just kick off and run side by side. All right. And the important thing to pay attention to here is the response of our one word output style versus our default Claude Cove style. They're both going to do the same work. complete and generate this new file right here. But the difference in the output and the difference in the consumption of tokens, specifically the output tokens is going to be larger. And we can look at this output style exactly concise, done. Check this out.

We have a list here of output styles. And you can see here, we are continuously reiterating this clock on output style to just say done. There are, of course, a couple exceptions to this. We don't always just want a point blank done response. If we ask our agent a question or something goes wrong, we of course want a more written out response. But most of the time when our agent is shipping work successfully, all it needs to do is respond with done. Which is what we're going to see here in just a second. So how you can see on the right side, side, our agent has completed and it's reported these output tokens to us here. And on the left side here, when our agent finishes, it's going to just report done. It's not giving us any extraneous extra detail, verbose information.

We know exactly what we need. asked just tell us if it was successful or if it failed. Okay, and so you know this might seem like a small thing. What I want to do is just showcase this simple idea so that you can understand at scale how important this is. Okay, so we'll paste this in and of course we can monitor our token usage. We can see point blank, this one response coming out of cloud code consumed 150 output tokens. Not too bad. Now, if we open up a new file and copy done, right, let's copy just done and we'll actually put this on the left. and we'll put this on the right. You can see here we have two tokens.

All right. So it's not the fact that this is a ton of tokens. It's not, but it's the fact that this is two tokens and this is a hundred fifty tokens. When we're running outloop agents as we start to get out the loop we don't need to be chewing up this you know 150 extra tokens across tens of prompts across hundreds of prompts and hundreds of agents okay every piece of context matters when you look at a graph of this stuff when you start to see your token consumption, you know this to be true. We have reduced our token usage here in this, you know, one element of cloud code down from 150. This is some massive 99% reduction in token usage. And it's all because we are controlling the output style of cloud code with a concise done prompt. There are other versions of this. You can find some better middle ground, but you can see very quickly how this is going to stack up. is a great way to conserve your token usage.

Now it's also important to note here that output styles do something interesting to the cloud code instance you're running. It effectively swaps the output style block in the system prompt, right? the output style block in the system prompt of cloud code. This is an interesting trend. Keep your eye on this. We're going to talk about the future of context engineering at the end of this lesson, some potential future directions that you can bet on. Let's go ahead and close our agents and move on to a big IT idea, a popular idea in the world of cloud code. Let's talk about sub agents. Now it's not just about using sub agents. This is about using sub agents properly.

When you use cloud code sub-agents, you are effectively creating a partially forked context window. Let's create a claw instance here. If we type context in an agent, a brand new agent, you'll notice something really interesting. We have custom agents here. All right, we have three custom agents that we can use. at any point in time. We can, of course, find these inside of Cloud Code under the agents directory. We can look at any one of these, right? Now, you'll notice something quite interesting. All of our agents here, our custom agents, only consume 122 tokens, whereas you can see my rough token counter is looking at 900 for this one agent.

What's going on here? What's the big difference? The big difference here is that when you're working with subagents, you are working with system prompts. There is a massive difference between the system prompt and a user prompt, right? When you're prompting cloud code, you're writing user prompts. When you're building reusable custom slash commands, you're writing a user prompt that all gets passed right into the agent. This is a system prompt, which is nice because it means that it's not directly added to our primary agents context window. Okay, and this advantage of subagents continues. With Clockwork subagents, we can delegate work off of our primary agents context window. This is a massive point for the D in the R&D framework, right?

It's delegation. We are keeping context out of our primary agents context window. For example, we can run slash load AI docs. And so this is going to load AI documentation from our AI It's going to read through all of these items. We can load up the AI docs reusable prompt, and it's going to kick off subagents to do this work for us. So our primary agents reading this file, and then it's going to kick off however many agents we need to to fetch every one of our agents are ADOC URLs, right? So it looks like, I don't know, what do we have here, 10 or 11. You can see this is gonna get kicked up here pretty soon after we do a date check on any file here that's older than 24 hours, which I think all of them are at this point. And so you can see it's removing these and then it's going to fire up these agents to reload our AI docs. There it is doc scraper.

And this is critical, right? A web scrape can consume quite a bit of tokens. And so we have this load AI docs reusable agentic prompt that's going to kick this off. the token starting to tick up. We already have 3k for each agent. This is 3k tokens times eight or 10 that isn't added to our primary agent. Okay, this is sub agent delegation. We're leveraging the context windows of our sub agents to do work and keep it out of our primary agent. All right. In this case, you know, this is a great use case for sub agents, right?

We have this workflow where doc scraper, you know, we have this system prompt here that details exactly how to. web scrape with fire crawl or web fetch, right? Whatever web scraping tool you want to use. It has it here. This would be a good example for us to fire up and load that one MCP server. But now these agents are just going to run the scrape which will consume their context window and then they're going to write the output files right so now we should see refreshed AI docs written here yep there they are and there it is yeah there's our success command here we of course are using a great prompt structure if we go back to load AI docs and collapse here. You can see we're using a classic agentic prompt workflow format where we have the purpose variables, workflow and report format. Definitely check out the agentic prompt engineering extended lesson to learn learn all of the powerful prompt structures you can use inside of both your system prompts and your user prompts like this. This is a classic workflow. We use a lot throughout TAC and throughout our extended lessons.

So you can see here all the tokens that were not added to my primary agent's context window. We can, of course, slash context to prove that. We're only up to 9K tokens, okay? We delegated work, right? We're stepping into the D in the R&D framework. There's only two ways to manage your context window. Reduce context. entering your primary agent and delegate context to sub-agents and as you'll see in upcoming techniques to other primary agents. Cloud code sub-agents have limitations. Sub-agents sit at the intermediate level for a reason because instead of keeping track of just one set of context model prompting tools, the core four, we now have to keep track of as many as you spawn subagents.

So it becomes super important to isolate the work that your subagents are doing into one concise prompt to one One focused effort. Remember a focused agent is a performant agent. Sub-agents are also a little trickier because of the flow of information. The flow of information in these multi-agent systems is critical. Your primary agent is primary. prompting your sub-agents and your sub-agents are responding not to you, but back to your primary agent. So once we start getting into this intermediate advance in a genetic level, we have to keep track of every agent's core four that we spin up. If you're losing track of a single agent, right, and you have a bunch of wasted context, you probably aren't yet ready for sub agents. You probably want to spend some more time cleaning up, managing and maintaining clean context windows for your existing single primary agent. Once you're ready, sub-agents are a great intermediate level, a great intermediate technique to step into because you can delegate the entire context window to one or more sub-agents as you saw here.

We say probably 40,000 total, tokens and ran all this work much faster than it would have taken a single primary agent. So next up, we have a powerful classic hack. We're continuing to push into the delegation of the R&D framework, you can have two agents working side by side. One agent plans, the other agent executes the plan. You have a planner and a builder, an architect, and an editor. This is a classic prompt chaining technique that expands. and extrapolates very well into the age of agents with your cloud code agents and with any agent. We have a reusable prompt in this code base called quick plan. All right. And all it does is if we open up quick plan, this accepts a, single argument, which is the user prompt.

Inside of TAC, you're very familiar with this pattern. We built out and extrapolated on this in the software developer lifecycle for the plan phase. But quick plan is roughly the same idea. You have a single prompt that's focused on just So let's plan some work, right? Let's push that cloud code TypeScript SDK a little bit further and create a small reusable code base inside of our application layer. So apps slash ccts wrapper. Okay, so let's fire that off. This agent is open. only going to plan. And now as you can imagine, if our agent on the left is only planning, we have a completely free context window on the right to build.

And so we of course have slash build. We can then take this build command and execute it on the generated by our plan agent. So we're going to let this agent cook and as you can see, we are continuing to reduce context windows and delegate work between agents. The idea here is simple. Separate your agent responsibilities. Because especially for your implementer, aka your editor and builder agent, you want their context focused so they can make surgical perfect error-free edits. A lot of engineers are stacking up a chat window, they're prompt chaining inside of a single agent's chat window over and over and over and they're not realizing that they're causing context rot and context bloat with every prompt that isn't laser focused to the task at hand. With our planning prompt, we have a detailed prompt in our classic instruction prompt format. Again, check out a Jentic Prompt Engineering extended lesson on the powerful prompt structures that you can write. And we're being very, very clear about what it needs to be.

to do. We're planning work and we're planning work with a powerful opus agent. Again, if you're in the future, I hope you have better, more powerful models use that. These techniques are all the same across models. Don't get stuck up on any one individual model, but You can see here our planner has finished planning. Now we can just copy this and we can be very confident that whatever is in here is up to par with our standards because we've put upfront investment into our planning phase. So I can just copy the reference to this and go to our build agent, paste this in, and with no context priming at all, everything the build agent needs is inside of this plan. It's all there because our planner took care of that for the builder, right? We are reducing context and we're delegating context, right? You can see our planner has consumed some 7K tokens here.

We're in a very small code base. And just imagine that this is, you know, a larger task, right? 60,000 tokens, whatever. You can be guaranteed that the tokens used to plan, not all of that is critical for the building. And this makes sense. When you're engineering, when you're writing plans, you always go overboard. By the end of your planning phase, you should be deleting information that isn't relevant to the work you want done. You should go overboard, then delete. Here we have the R&D framework in full swing. We're delegating across two agents to reduce context when it matters most.

There are a lot of places where it matters, but when your agent is actually writing the code, when they're actually running your agentic workflows, that's when it matters the And this context window here that's doing all this writing, right, it's chewing up our expensive output tokens. It's a focused agent with a focused context window. And that means it is a performant agent. All right. And just to detail that prompt a little bit more. Or if we run up a little bit, here's what this agent is planning just to give a little bit of more additional context here, right? Quite simple, so quick plan, and then here's the prompt that we're actually executing. Read TypeScript SDK, create reusable three file wrapper system for calling agents, via cloud code, TypeScript SDK. Here are some methods. Types file, low-level CLI file.

Create this in this directory. All right, so just a simple kind of high, mid-level prompt. And our builder has finished implementing. We can just open up this directory and we can see exactly what was created. There's our hello. calls and then inside of this directory you can see here we have a full-on application built out we can of course CD apps CC bun run tab there's everything our bun ecosystem is giving us we can just run it's run dev looks like I'm gonna prompt, hello, enter. And now the cloud code SDK via TypeScript is running. There's the response, session ID, fantastic. There we go. So simple prompt, simple planner, builder, workflow, architect, editor, delegating across two context windows.

Let's take our builder and let's run a very well-meaning feature inside of cloud code. A very powerful, useful feature slash compact. Okay, so you've probably used this one, but there's a huge problem with this command after compact runs do you know exactly what's in your context window every single time now the answer to this is of course no you don't know I don't know we have to hit control R and reread through what this this compact ended up doing. When you get to advance agent encoding, it's time to stop guessing and start knowing. I avoid compact and I recommend that you reset and prime. You know, we can hit control R here. We can see a decent summary here, right? Some nine steps summary. You can imagine the cloud code engineers have some type of prompt that generates a step-by-step workflow. You can see it is summarizing decently here.

Usually it has some type of read file command where it automatically reads some additional files, right? You know, you can understand why they did this, the context window is limited. They're facing the same limitations as you and I, and they want to provide solutions for them. But just like your prompts, the context window of your agents should not be handed off to any tool or team. The compact command for what it's worth is great, but it's a band-aid fix for the true problem. The context window has grown large and cannot fit any additional information. Instead of compacting, instead of running slash compact, I recommend you run slash clear. blow away the context window completely. Now if we run slash context, we are running a fresh focused agent. Now reset with slash prime, right?

Run whatever prime command you're running and refocus. on your task at hand, right? Build back up to where you were and continue forward. I know this one doesn't sound great. It's like the first advanced technique basically just saying do more work. Don't depend on the slash compact command. Why do we do this? It's because this way you know exactly what's in your context window and you get in the habit of building task specific context priming prompts. All right. Just like our beginner techniques adjusts.

These techniques stack up on each other very, very quickly. The big idea here is you don't want to delegate the control of your context window. All right, this is a dangerous game to play. You want to own this just like you want to control your prompt or your model. The context window is the same. This is also important for Outloop agentic coding, right? It prepares you for Outloop agentic coding. And for this to work at high levels across hundreds of agent executions, you need specialized agents where you know what the context will be. If a compact command runs, you can't know this with high confidence. For Outloop agent decoding, no single agent agent should overflow their 200k tokens and trigger a compact.

If it does, you should chop up the task. You shouldn't need slash compact. And if you need to, you should reset and prime. Now, we can push this idea a little bit further and try to do what the compact window command is doing ourselves with our next advanced context engineering technique. Notice that with each technique from beginner to intermediate to advanced and soon agentic, We're doing R and D, reduce and delegate. We're keeping track of our context window at all times and we're not outsourcing it. If you want to scale your agents, monitoring and managing the state of your context window is critical for your success. All right. Just like context priming, you can push in loop active context management even further with context bundles. So with Cloud Code hooks, you can hook into a couple of tool calls to create a trail of work that you can use to reprimand your agents for the next run, right?

So you can chain together agents after the context window has exploded. So the great part here is we've been using context bundles the entire time. So let's collapse everything and open up agents. And so agents is becoming a additional agentic layer directory where you can just put output from operations of your agents. You can see we have background and we have context bundles. Let's click into bundles and let's see what we have in this directory. All right. So if we click this bundle, we have something super simple. slash prime and we have read. If we click into this context bundle, you can see we have our quick plan.

So this was the work that happened inside of our planner. It read the file as specified and then it wrote this plan here for us, right? And we have the tool input. And we have a couple of other things, right? This is powerful. This is a context bundle. What we have here is a simple append only log of the work that our cloud code instances are doing. These are unique based on the day and the hour and the session ID. So how does this work exactly? Fire up a YOLO dangerous mode instance, and we just type prime, right?

Let's just rerun a prime and let's prime our cloud code, right? So we're running our prime command around cloud code. And you can see this context bundle was generated, okay? So there's the prompt and let's just, Pay attention to what this does. All right. We have read commands. We have search commands. Our read commands are all getting appended piece by piece. And what this does is it gives us a solid understanding of 60 to 70% of what our previous agents have done. And so why is this important?

This is important because it tells a fuller story for subsequent agents to execute. There's a bunch of additional read commands and we're getting a log, right? We're getting a full-on context bundle of our agents' comments. context window. This is a very simple yet powerful idea you can use to remount instances to get them into the exact same state after their context window has exploded. It also gives us a story because we have the prompt operation in here. about what the context is and why the context is that way based on our user prompt, okay? So, you know, we have this now, great, who cares? Let's open up a new cloud code instance. And let's say that this, you know, this agent's context window exploded.

We can with this context bundle. bundle run slash load bundle copy the path paste it hit enter this agent is now going to get the full story of the previous agent it's going to deduplicate any read commands and then it's going to create an understanding of the done up till this point. And so imagine this is much larger, right? Let's say that it's something like, you know, 50 plus lines of reads and writes. We can use a context bundle to get a much more accurate replay of what the previous agent was trying to do. You can see here in the summary message very concisely. The previous agent executed this command and loaded key findings. That's it. Nine files. You can imagine this getting a lot more complicated with reads, writes, and additional prompts.

But with this simple pattern, with this session ID, getting tracked here inside of this context bundle we're saving a concise execution log thanks to cloud code hooks that we can reference in subsequent agents and the great part here is of course you can conditionally use this a lot of the times you won't need to reload the entire context bundle because it won't be relevant. But if we needed to, we could get the entire replay of the agent up to the point in which the context overloaded without all of the writes and without all the details of all the reads. The trimmed down version is super important, right? We're not recording every operation. If we do that, we'll just end up overflowing the next agent's context window. So you do have to use this selectively, but this gets us, you know, 70% of where the previous agent is. agent was gets us mounted and restarted very quickly. This is another advanced contact engineering technique you can use. Check out this code base for the details on how exactly this works. Our last advanced technique is It's a simple idea.

It's a beautiful idea. It continues to build on the techniques we've worked up to use one agent for one purpose. Maybe you've picked up on this with some of the repeat themes that we're getting into, but there's no better way to control and manage your context window than to ship. one thing at a time. A focus agent is a performant agent. This advanced technique forces you to sit down and answer the question, what does the pipeline of agents look like for this work? OK, once you start doing this well, And you understand the idea of using one agent for one purpose. If you've taken TAC Lesson 6, you know the full version of this. But once you start doing this well, you'll start engineering and problem solving in this two-step workflow. First, you plan out the work you want done without regard for technology.

Okay, you'll focus on just solving the problem for your users, for your customers, right? Always remember your users and customers come first. The technology we use is a means to this end. Then you'll plan out how you'll will delegate your work across several agents, forming an agentic pipeline, also known as an AI developer workflow, the highest level of agentic coding leverage as discussed in TAC. We'll move on from this big idea since it's the key idea in TAC Lesson 6. But this is a massive way to manage your context windows. This idea takes agent delegation to its natural, most valuable limit. Use one agent for one purpose so that your context Windows are focused. A focused agent is a performant agent. Now we've reached the agentic level.

Here you've mastered all the previous levels of context engineering. This is where things get powerful and dangerous if you don't know what you're doing because your patterns will start to scale into the agentic workflows into the ADWs into the pipelines that you build. So let's focus on the system prompt. You can massively control. Claude code's behavior and really any agent's behavior. This can completely change how the tool works even more than output styles, because we can control and start to overwrite the default Claude code behavior. I'll say it point blank. engineers will not get to this level. Many engineers don't need this level. But if you're pushing to the edge, the system prompt gives you even more control over your agent and therefore the context flowing in and out of your agent.

If you start down the path of agentic engineering, at some point, you will need to crack open and modify the system prompt. This is how you build your agents and gain fine tuned control over your agents and therefore your context window. There are two flags. in the cloud code CLI and the SDK. And I'll write the full prompt out here, right? So I usually run CLDYS, right? Clawed Dangerous Sonnet. Let's go ahead and just paste this in here. Then we'll run PEND system prompt. And then we'll pass in our specific specific system prompt.

When you start modifying the system prompt, you can't run this in the loop, okay? So you can't open up an instance, at least not at the time of filming, okay? You have to run this in print mode, in programmatic mode. This is where we start pushing out the loop. So we do need this dash dash print or just dash P flag and then we run a prompt. So I'll say what is cloud. md for? And so that was the large, you know, context file that we demoed in the beginning 18,000 tokens. Then I'm going to paste in this system prompt. And so check this out.

Important when using the read tool, always read in increments of 100 lines. For example, and then I give an example being really detailed with how to call this tool exactly and then If you read enough to accomplish the requested task, stop reading and proceed with the task. If you need more information, read another hundred lines and determine if that's enough. And then we have one more instruction. We're tapping into an information tense keyword. When you respond to the user with your final message, always prefix your last message with check or X for success or failure. All right. And so this agent has been modified, right? We've modified the system prompt. We are controlling this agent at a lower, more foundational level.

The system the prompt really lets you start controlling how your agent behaves. And when you control the behavior, you control the context window. So let's make sure I end the quote here and let's fire this off. You can see here we have a concise response demonstrates what not to do with project Intentionally bloated using anti-pattern of over contextualization, cramming, excessive details, blah, blah. Okay, so it understood it ran. The interesting part here is how it ran. If we open up our context bundle and we go to this context bundle, that just ran you can see something really powerful okay what is this file for you can see our prompt and you can see the subsequent reads read 100 read 100 this agent is obeying the specific instructions in our system prompt we're saying read 100 lines out of time. If you have enough information, stop executing and respond, right? Proceed with the task. This is super, super powerful.

We've just reduced the number of lines our agent had to read with the read tool, okay? And we force cloud code to increment. Okay, this is super powerful. And this is just one simple way, right? One simple control mechanism for steering this agent in a completely different direction. You can push this even further using the cloud code SDK in addition to the PEN system prompt command. There is also a SDK specific custom system prompt variable that you can pass into the SDK. I do not use that unless you know what you're doing. Okay, the Cloud Code team has put a ton of work into crafting the system prompt prompt to be a top tier agent for engineering. If you use, I think it's called a custom system prompt, I'll of course link all the documentation below in your loopbox.

But if you use this variable, you will blow away the system prompt. Use this with caution. And so we can run another one. So we have another prompt here. Same deal. We're reading in chunks of 100 figure out what cloud code hooks are available and their respective input schemas from the documentation. So I'm going to fire this off. Here's that context bundle running. You can see that same deal. There's all the response formats for every hook based on the existing documentation and there's the available hooks, but you can see here again in the context bundle we're saving the actual read executions and the tool input.

written the calling mechanism for reading files. You can see there that same pattern reading 100 at a time of the Cloud Code Hooks directory. For this one, it needed to read more to accomplish this task. So it did. I recommend you only use this agentic level context engineering technique when nothing else works or when you start building your custom agents for your domain specific use cases and when you start deploying agents inside of your code base. Check out the Agenda Horizon extended lesson on Claude Code SDK management. Then we break down the cloud code SDK so that you can run this in a more programmatic way so you can build out specific agents inside of your code bases. This is where everything is going. Specific agents with specialized context windows solving your problems extraordinarily well. The focus should always be better agents or more agents.

When you're adding more agents, you're pushing into the D, the delegation, and the R and D. You're pushing it to the max. You're using one agent for one purpose, and when something goes wrong, you fix that piece of your workflow. Now with primary multi-agent delegation, we're entering the realm of multi-agent systems. And TAC, with each lesson, we built up variants of a multi-agent pipeline using this very technique. And in lesson eight, we showcase several different multi-agent workflows and systems and UIs. There are many ways to delegate work at a high level, but when you get down to it, if you want to create an on-the-fly primary agent, you have two options. You have the CLI and you have SDKs. At the mid and high level, we can kick off primary agents through prompts, through wrapper CLIs, through MCP servers, and through UIs. You've likely seen a lot of cloud code management systems and a lot of agent systems get built up into their own UIs.

That is primary agent delegation. Now, what's the most lightweight version of multi-agent delegation you can use? ASAP and get value out of ASAP. It's a simple reusable custom slash command. If you remember inside of the cloud directory, in our commands directory, we have background. This is a simple single prompt that boots up a background cloud code instance. This is the simplest, quickest way other than going right through the CLI to delegate work to agents. When you use a pattern like this, we're pushing in to powerful Outloop agent decoding by running a single prompt with a single agent that does one thing, reports its work, and then it finishes. So let me show you exactly what I mean. I'll run Claude Opus in yellow mode here and then I'll say slash background.

And you can see here this fires off a full instance in the background. Here's our argument hint prompt model report file. I want to kick off the creation of a plan. There's no reason for me to sit here in the loop prompting back and forth when I can kick off a background agent, when I can delegate this work outside of my primary agent's context window, right? We're delegating this work out. I can open up some quotes here, paste this in, and this is going to kick off a new quick plan. So we're running that plan workflow, that plan agentic prompt again. This time we're building out a Cloud code, these are just random code examples. We're going to read a couple pieces of documentation and this time we're building out a Astral UV Cloud Code Python SDK with that same format, right? Those three files, bi-dantic types, low-level files, CLI file, right?

specifying where to create it. This is the plan. Let's fire it off. This is going to kick off a background agent, okay? And so you can see our primary agent getting to work here based on the contents of this prompt. We can of course see that consistent prompt format where you're reusing great prompt structures that get work done for us. Again, check out the Agentic Prompt Engineering Agentic Horizon Extended Lesson to learn how to write great prompts for the age of agents, and it's all inside of the workflow step here, right? So, So create the agent's background directory. We have our default values. And then this is important.

We're creating a report file. And then we have this primary agent delegation XML wrapper where we're detailing a bunch of information for our agent. We are kicking off a close. Cloud code instance from cloud code. We have compute orchestrating compute agents orchestrating agents. Okay, this is where everything is headed. Better agents and then more agents. Once you master a single context window, you can scale it up. There's a format. blah, blah, blah, skip to the bottom.

But the important thing here is that this frees up the primary cloud code instance. You can see we have a background task background cloud code kicked off. If we open this up, this is the file that our agent is going to be reporting to. And so cool thing here, we can open up the content. context bundle for this agent, right? So if we hit up here, you can see that exact prompt background slash quick plan read blah, blah, blah, blah. This agent is starting to work. All right. It's starting to create this plan. And we can see that with the context bundle.

You can see this is super. useful adding logging having these trails there's the actual plan just got written there having this this trail the story of what your agents have done is an important agentic pattern we are building up on every context engineering technique we've used used thus far. This agent should report back to its report file here. This is a great way to track the progress of your agents as they work in the background. So you can see here we still have that one background task running. We should get an update here. Our agent has, there we go. So you can see it's reading its background file now. And then soon it's going to put the right in here. We should see this come in live as our background delegated agent instance.

It's just writing this plan for us. There's no reason for me to sit in the loop. I know exactly what this does. And here, is the output. Check this out. Progress, task completed. It renamed this file. I have an instruction to rename the file when it finishes. We can click this. It is now complete.

A very quick one agent delegation system. It's all here for you in this code base. Think of these as starting points for understanding what you can do to better manage the context of your agents. It's all about the patterns. It's all about taking control of your agents context windows and scaling it to the moon. The more compute you can control, the more compute you can orchestrate, right? The more agents you can orchestrate, the more intelligence that you can orchestrate, the more you will be able to do the limit. on what an engineer can do right now is is absolutely unknown. Anyone being pessimistic, ignore them. You know, don't take my word for this.

You know, ignore me as well, but investigate the optimist in the space. See what they can really do. See what they can do. but see what we're really doing here. Okay, we have background, compute, agents calling agents. We have the R&D framework, 12 context engineering techniques. These are concrete things. Maybe a couple of these techniques fly over your head or you're not interested, or you think it doesn't apply you that's fine just take one take a couple of these and improve your context engineering okay the background agent task and multi-agent delegation is super important because it gets you out the loop all right this is a big idea we discuss and and it extends into context engineering. Okay, get out the loop, set up many focused agents that do one thing extraordinarily well. All right?

In a lot of ways, multi-agent delegation is just like subagents, but we get complacent beat control, right? We're firing off top level primary agents from our in loop primary agent here. So there's a lot more control here. This background agent and the prompt that I passed in, right, we can just paste this prompt. I could have asked for anything here, right? This doesn't need to be a quick plan. I could have asked for a, a, you know, multi-agent workflow running sub-agents, right? There's just so many ways to build and to use multi-agent systems. The key idea here is let me Let's bring it all back to context engineering. The key idea here is you can delegate specialized work in focus agents by building out some type of primary agent delegation workflow.

You can see here in just one prompt. We have a full cloud code instance in the background doing work for us that we know we don't need to monitor anymore. And the more you become comfortable and the more your agentic engineering skill improves, the more you can stop babysitting every single Asian instance. Okay, this is a big theme in tech. We want to scale from in-loop to out-loop to ZTE. Speaking of specialization, speaking of all these big ideas, let's wrap up with potentially one of the most powerful context engineering. Let's talk about agent experts. So what does this all build up to? We've already covered the main idea, right? Build focus agents, deploy them in ADWs with specialized pipelines, protect your context window at all costs inside of every agent.

But once you put all this together, you can get something really special, something really powerful. There's not really a name for this yet, but I've been just blatantly calling this pattern agent experts. The idea is simple and powerful. especially for context engineering with agents on large code bases. Okay, this idea is echoed inside of TAC with templates. You can use your agent delegation of choice. You can use your primary agent, primary delegated agent or a sub-agent. The whole idea is that you fire off specialized agents that are experts at specific parts of your code base. And here's the kicker, you have them auto update their own knowledge. This is the agent experts technique.

Let me show you exactly how. Inside of our Claude commands directory here, we have an experts directory. Right now we have a single expert in this code base, and you can see this agent expert is focused on Claude code hooks. Now before we move forward, let me just kick off this So I'm going to run this prompt and I'll just paste this in for brevity. I'll type slash experts. And so now we can just see all of our experts and I want our planning cloud code hook expert. And now we'll paste in a prompt. Okay, so I'm going to paste this in. This is a simple high to mid level prompt. relatively void of details.

We want our expert to take the wheel on this. So what does this do? Long story short here is you can pause the video and read it if you want. We're going to create a output structure. So we have agents hook logs for every cloud code instance. full log of every event so we can improve our agentic coding, right? We want additional monitoring. So how we're going to do that, we're going to have our cloud code hook expert build this directory structure. Agents, hook logs, session ID, name of hook. Let's fire this off and let's understand what our expert can do.

All right. So let's open up this prompt. We want the Cloud Code Hook Expert Plan. This is going to look very similar with an additional section that you probably haven't seen before. expertise section. Now this section on its own, it's not that useful. It's not that different really than our instructions or our workflow. But the key here is we have a three step Asian expert. Let's open this file explorer up again. And you can see here we have plan build improve and it runs in that flow.

Okay, so this agent right now is planning for us. It's a specialized Cloud Code Hook Planner agent. So it's built just for planning Cloud Code Hook related functionality. pass it off to our expert builder, which is going to take the path to the spec that our planner created. And the agent that runs this prompt, as you can imagine, is going to be specialized to running Claude Code hooks, right? You can even see the directory structure all the relevant files to this specific piece of our code base, right? You can see here we're building experts. We're not building random one-off agents, random agent instances. We've built a reasonable prompt that mounts and you know, go all the way back to our beginner techniques. We are in a way priming this agent to be an expert at this area of focus.

A lot of the work I do is aimed at showing you the vision and giving you the new beliefs and the new ideas, the new context that you need to deploy agents, to deploy generative AI in new forward leaning ways. Okay, so this is just one idea, but you can imagine multiple experts across your code base that are extraordinary. They're like the engineer on team that knows that one piece of code, that one feature better than anyone. Now you can encode this, you can template it into an expert, an agent expert. And here's the cherry on top. After you implement the plan, after you have your expert build it, right? It's specialized at building this specific type of work. You can run your meta improvement expert. You're a cloud code hook expert specializing continuous improvement. You will analyze the work done, blah, blah, blah, and update.

your plan and build experts. So we have a prompt built to improve our prompts. Okay, we're very close to the edge here and you can see where this goes for you, right? It's auto documenting, it's self-improving. Let's Let's go ahead and continue this workflow. You can see here our spec got created. You know, we have a great spec here detailing exactly how this works. Feel free to pause at any point. And I'll go ahead and just commit this work with the Elite Context Engineering code base so that this feature will be built out. We'll be logging this structure by the time you get your hands on this.

All right, I'm gonna copy the reference to this. I'm going to, of course, I'm not gonna use this existing context window if we type slash context already spent 26K, even though we could chain on top of this agent, we are not, we are practicing to saying we're preparing for Outloop agents. We're thinking about this as if we're building a pipeline of agents. I'm going to open a new instance here, Claude, Yolo Mode, Opus, and then I'm going to type slash expert. We're going to build this feature We're going to paste in the path and let this fresh, focused agent cook. We have one agent planning. We have the other building and we have the last self improving. Whatever changes we make to this system are improving. prove expert, our sub prompt, our sub agent inside of this three step expert is going to look back at the changes made and update the plan and the build to have the details of the implementation. The planner thinks about what needs to be done and then its context window is gone, right?

We don't need it anymore. The builder takes the plan and actually implements it, right? This is a classic pattern, big shout out to the legacy AI coding tools, the old school tools, AIDR and all the other tools that separated planning and building. This is a pattern that is going to continue across. And as you saw in TAC, this pattern can continue and expand across the software developer lifecycle. Here's our new hook logger getting built out, CH mod. It has everything it needs to deploy this into single file scripts, right? It has the information. It is an expert. I've built an expert set of agent prompts into the code base.

This is what it looks like to continuously build and improve on the agentic layer of your code base. You're going to end up with experts, okay? Asian experts that can remember and build and improve on areas of your code base that you will not remember anymore. You know, even the engineers you know you just we just lose track of this stuff over time all right that's natural but now we have Asian experts and yes this is a another you know investment you have to make into your code base you have to maintain your Asian experts but this is going to be it looks like our hooks are coming in now let's go ahead and look at agents hook log and you can see there there's a couple test runs coming in it looks like this agent is starting to validate their own work with a closed loop prompt you can just start to see this stuff stack up very quickly okay so This has been elite context engineering. All right. This is where it all goes. Once you master the context window of a single agent, you can make your agent do more because it has more space. It's focused and then you can scale up how many agents you can control and steer at any one point in time. So now we have this implemented. Let's see.

You always want to review the work. You know, at a high level, I can just quickly come in here and see that looks great. Universal Logger. Okay, looks great. It is adhering. It is aligned. Now if we open up a new instance here and kick off Claude, you can see we have this feature built out exactly as specified. So there's the start session JSON L. We can type hi. We're going to get whatever the user the prompt submit and then we're going to get some flows coming in.

Let's go ahead and run, right? We got a stop command. Let's go ahead and run prime. This is going to run a series of operations, right? Let's go ahead and kick that off. And then you're going to see the logs come in. That was built perfectly in one shot with a planner and a build as an expert, right? These are agent experts. Let's run the final step and let's talk about the future of context engineering, okay? So we're going to run this new cloud code instance in YOLO mode.

You can see that log got appended there. Our agents, right, and our systems or a genetic system is keeping track of all types of things now, log hooks, context bundles. We can fire off background agents if we want. But all we want to do now is expert improve. No params. We just improve. And it does this by looking at the git diff it looks at any changes and then it makes the improvement to our existing build and plan cloud code hook expert in our code base okay so you're gonna see these changes here flow in you can see our expert is preparing it's priming itself to improve what's been done. It's gonna run a get status in a second here and see any relevant changes that are relevant specifically for the files it has detailed. And you can check out the prompt, of course, in this code base classic, great, agentic prompt engineering in all of our prompts here. But you can see it's doing this work and it's going to self-improve.

There we go. I've identified several changes, relevant learnings, relevant changes from the universal logger implementation. That looks great. If your code base is large or you have a highly technical area that requires your expertise or another engineers on your team. You know, I highly recommend using the agent experts pattern. Of course, you'll have to maintain and monitor your expert, but this is much better than having it stuck in your head or an engineer's head, right? You want you want your agentic layer operating your code base and you operate the agentic layer, right? You know this if you've taken TAC. We build the system that builds the system. Our improving meta agent expert is now updating based on the git status right based on the git you know git execution run it's updating our build and plan and here's the summary of what was changed right it just added a couple sections to the expertise section okay so we have a dedicated section inside of built for this.

We're following great agentic prompt engineering. We're not conflating our headers. We're not conflating our sections. It's very important. And this pattern, the agent experts, it brings us right back to the highest leverage point of agentic coding. both our plan and our build dedicated to specific expertise that gets updated on the fly. It's dedicated. It's differentiated. We don't want this to be in the workflow or in the purpose or in the instructions. We have a dedicated section.

the ADW, the AI developer workflow. You can imagine a workflow in ADW where we string together these three prompts in three individual agents. Plan, build, pass the plan into the build, and then improve and then we run our git commits after, right? This is an entire workflow. All we do is pass in some prompt, a high level prompt that we want. And then this workflow, this specialized agent takes it from there. There are many directions to go with this. You can imagine a, a router agent that takes in any high level prompt and then determines what expert to run. There are many ways and directions to take this, but I wanna leave that up to you. Take these 12 techniques and apply them.

Get value out of these techniques. All right. Yes, it takes some time. Yes, you have to invest. This is not vibe coding. If it's easy, a vibe coder is probably doing it and that isn't irreplaceable. That is replaceable work. Even one of these can save you massive time. If you have 12 here, pick one, pick a couple, dive into them, deploy it into your Agenda coding to improve your context engineering. Managing your context window is the name of the game for effective Agenda coding.

And remember, it's not necessarily about saving tokens. It's about spending them properly. We manage our contracts window so that we don't waste time and tokens correcting our agents' mistakes. We want one shot out loop agent decoding in a massive streak with the fewest attempts at sizes so we can drop our presence, right? In TAC, we use specialized agents. We delegated and we reduced the context window of our agents by building specialized ADWs that shipped on our behalf. So the big idea here is simply Let's measure and manage one of the most obviously critical leverage points of agentic coding, your agent's context window. Here are a few future context engineering trends you can bet on coming out of the big AI labs. You can imagine larger context windows. All right, this is obvious and self-explanatory.

We want more context to get around the compact problem. Right next to that and very, very closely related, we are likely to see better context windows coming out of these big labs. Language models, they tend to lose massive capability as the context size grows. This is an attention mechanism problem inside of modern agents. You can plan and bet on big labs focusing on better effective context windows. Okay, another big idea here is hot swapped context windows, hot swapping tools, hot swapping context in general, right? Hot swapping the system prompt like cloud codes, output styles enable us to do, right? You can overwrite and therefore hot swapping existing system prompt. This is an important, pattern. Imagine for every piece of context, user prompts, assistant prompts, tool calls system, you can swap in and out different contexts, right?

You can delete context to free up the context window. Hot swapping context is a big idea we're likely going to see. And then The last two are very obvious. You can see these. If you're on the edge, you're already doing this. And you're using TAC to help you get there faster, quicker, better. Multi-agent architectures for agent delegation. Okay, we touched on this several times throughout TAC. And here we use subagents and primary agent delegation. And then lastly, a big trend you can bet on specialized agents everywhere on the bleeding edge.

You plug into the cloud code SDK and other agent SDKs and you specialize every element of the context, the model, the prompt, the tools. to solve and deliver unique experiences for your users and for your customers. Okay, what's better than a prompt? A prompt chain. What's better than a prompt chain? An agent. What's better than an agent? Many focused, specialized agents that deliver value for you, for your team, and most importantly, for your customers and users. Don't miss this trend. You now have everything you need to win and ship with focused, single purposed agents.

So all these techniques are us battling with the fact that there are key scaling laws and algorithms inside of these language models, inside of generative AI that decreases performance as context window grows. What does that mean? It means you can safely bet on spending your engineering time, energy, and resources on investing in great context management, in great context engineering. It's a safe bet to bet on context engineering. You know, with all the focus on context, let's not forget about prompt engineering and specifically agentic prompt engineering. If you're writing bad prompts, your context doesn't matter. All right. If you can't communicate what you want done with your agents when you're delegating and when you're reducing context, you're going to be massively limited and you're going to be shooting yourself in the foot. money, right? If you want to write the best prompts and preserve your context window, you want to be stacking up these big ideas.

You'll get a ton of value out of the agentic prompt engineering extended lesson I've built out for this very purpose. agentic horizon lesson is dedicated purely to agentic prompt engineering in the age of agents. We'll be optimizing prompts for cloud code, but really all agentic coding tools. We're betting on the winner and we're preparing for competitors. And of course, if you want to build specialized agents, check out the cloud code SDK mastery. You want to be using the cloud code SDK and agent SDKs to solve your domain specific problem better than any chat interface or any prompt or any generic cloud code instance. All right. So check out the Cloud Code Mastery extended lesson to build your own custom agents. Fantastic work here. There is a lot to digest.